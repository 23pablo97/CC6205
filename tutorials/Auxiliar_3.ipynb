{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Auxiliar_3_Text_Classification_FF_pytorch.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jII_E6_9GzC-",
        "colab_type": "text"
      },
      "source": [
        "# Practice Class 3 - Text classification with pytorch\n",
        "\n",
        "\n",
        "Agenda: \n",
        "\n",
        "- What is pytorch \n",
        "- Pytorch: Autograd\n",
        "- Dataset\n",
        "- Indexing\n",
        "- BoW\n",
        "- Creating the model\n",
        "- Batching and padding for BoW\n",
        "- Training\n",
        "- Creating the model with embedding\n",
        "- Batching and padding for embedding\n",
        "- Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Fu0P-_dDrC",
        "colab_type": "text"
      },
      "source": [
        "Note: This notebook is designed to run in sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4E6l9b-nSj1",
        "colab_type": "text"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKeAKWooGzC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from spacy.lang.es.stop_words import STOP_WORDS\n",
        "from sklearn import preprocessing\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from os import path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDni9Mds9fSi",
        "colab_type": "text"
      },
      "source": [
        "#Part 1: Pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CArzbvZBTa5R",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##What is PyTorch?\n",
        "\n",
        "\n",
        "It’s a Python-based scientific computing package targeted at two sets of\n",
        "audiences:\n",
        "\n",
        "-  A replacement for NumPy to use the power of GPUs\n",
        "-  a deep learning research platform that provides maximum flexibility\n",
        "   and speed\n",
        "\n",
        "##Getting Started\n",
        "---------------\n",
        "\n",
        "Tensors\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that\n",
        "Tensors can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UumpLon0Ta5d",
        "colab_type": "text"
      },
      "source": [
        "Construct a 5x3 matrix, uninitialized:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoIccJtnTa5f",
        "colab_type": "code",
        "outputId": "044b0066-db71-48a9-8773-787be19884e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[9.3372e-38, 0.0000e+00, 4.4842e-44],\n",
            "        [0.0000e+00,        nan, 3.2167e+38],\n",
            "        [2.0432e+20, 1.6899e-04, 4.2469e+21],\n",
            "        [1.6875e-07, 6.6646e-10, 2.6726e+23],\n",
            "        [2.6196e+20, 4.2465e+21, 7.5883e+31]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m24Pd_DqTa5o",
        "colab_type": "text"
      },
      "source": [
        "Construct a randomly initialized matrix:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exkGpVW5Ta5p",
        "colab_type": "code",
        "outputId": "23014d7a-6750-42ff-fb30-086a3a853bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4486, 0.5735, 0.0050],\n",
            "        [0.8929, 0.5180, 0.9065],\n",
            "        [0.9002, 0.7611, 0.8561],\n",
            "        [0.0886, 0.2831, 0.7496],\n",
            "        [0.3759, 0.6037, 0.3632]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTvcBc2GTa5w",
        "colab_type": "text"
      },
      "source": [
        "Construct a matrix filled zeros and of dtype long:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8CE8y9RTa5y",
        "colab_type": "code",
        "outputId": "365138a1-4fe2-4306-81d4-5396039ae4cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1JjB4UxTa51",
        "colab_type": "text"
      },
      "source": [
        "Construct a tensor directly from data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UX6Ao5uTa54",
        "colab_type": "code",
        "outputId": "12954541-971e-4b91-8bd3-0e8668071534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIszfThFTa59",
        "colab_type": "text"
      },
      "source": [
        "or create a tensor based on an existing tensor. These methods\n",
        "will reuse properties of the input tensor, e.g. dtype, unless\n",
        "new values are provided by user\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6MO1o5RTa5-",
        "colab_type": "code",
        "outputId": "78ae742f-bab2-44ca-b639-977f40be78fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[ 0.4953,  0.0618, -0.7314],\n",
            "        [-0.3911, -0.4672,  1.3973],\n",
            "        [ 0.3247, -0.2843, -2.2779],\n",
            "        [ 1.6778,  0.4859,  0.7947],\n",
            "        [ 1.1966,  0.6109,  0.5748]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDGcdRNzTa6D",
        "colab_type": "text"
      },
      "source": [
        "Get its size:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjtTuYYKTa6E",
        "colab_type": "code",
        "outputId": "c6d4c676-5bd2-4fe1-e4cd-693ee330c39e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlXggCYqTa6J",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n",
        "\n",
        "**Operations**\n",
        "\n",
        "There are multiple syntaxes for operations. In the following\n",
        "example, we will take a look at the addition operation.\n",
        "\n",
        "Addition: syntax 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fu_9WnqTa6K",
        "colab_type": "code",
        "outputId": "82fb50a6-13b0-408e-eee6-2172c4e50cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7823,  0.6407, -0.5979],\n",
            "        [ 0.4032,  0.5036,  2.1342],\n",
            "        [ 0.4818,  0.5623, -2.1194],\n",
            "        [ 1.8993,  1.3681,  1.3683],\n",
            "        [ 1.6051,  1.2291,  1.3530]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4AC8nTKTa6O",
        "colab_type": "text"
      },
      "source": [
        "Addition: syntax 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEmrQSk0Ta6P",
        "colab_type": "code",
        "outputId": "2cc6d0d8-9f24-4630-b6c7-df13729b62ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(torch.add(x, y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7823,  0.6407, -0.5979],\n",
            "        [ 0.4032,  0.5036,  2.1342],\n",
            "        [ 0.4818,  0.5623, -2.1194],\n",
            "        [ 1.8993,  1.3681,  1.3683],\n",
            "        [ 1.6051,  1.2291,  1.3530]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GyBdfmyTa6T",
        "colab_type": "text"
      },
      "source": [
        "Addition: providing an output tensor as argument\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi9-U-57Ta6e",
        "colab_type": "code",
        "outputId": "11eda56f-ef57-498b-e4a5-d19843ecb6b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7823,  0.6407, -0.5979],\n",
            "        [ 0.4032,  0.5036,  2.1342],\n",
            "        [ 0.4818,  0.5623, -2.1194],\n",
            "        [ 1.8993,  1.3681,  1.3683],\n",
            "        [ 1.6051,  1.2291,  1.3530]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm0WO501Ta6h",
        "colab_type": "text"
      },
      "source": [
        "Addition: in-place\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQY9Wp2qTa6i",
        "colab_type": "code",
        "outputId": "9b0b359e-cb4f-4c8b-f787-855499894dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7823,  0.6407, -0.5979],\n",
            "        [ 0.4032,  0.5036,  2.1342],\n",
            "        [ 0.4818,  0.5623, -2.1194],\n",
            "        [ 1.8993,  1.3681,  1.3683],\n",
            "        [ 1.6051,  1.2291,  1.3530]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsapeJYCTa6l",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
        "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
        "\n",
        "You can use standard NumPy-like indexing!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsZK2ikYTa6m",
        "colab_type": "code",
        "outputId": "6b5cc59b-3c0e-4c96-ea53-795c0f1523c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y[:, 1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.6407, 0.5036, 0.5623, 1.3681, 1.2291])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJsuwmuHTa6r",
        "colab_type": "text"
      },
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf6rgMalTa6s",
        "colab_type": "code",
        "outputId": "232e007f-7b4a-4270-a210-8a0c63c17a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7q2SWc6Ta6z",
        "colab_type": "text"
      },
      "source": [
        "If you have a one element tensor, use ``.item()`` to get the value as a\n",
        "Python number\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJO8VXR1Ta6z",
        "colab_type": "code",
        "outputId": "206ea19f-a34a-4a84-a2bc-9eb56c070a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.3467])\n",
            "-0.34665921330451965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHHlHBYvTa63",
        "colab_type": "text"
      },
      "source": [
        "**Read later:**\n",
        "\n",
        "\n",
        "  100+ Tensor operations, including transposing, indexing, slicing,\n",
        "  mathematical operations, linear algebra, random numbers, etc.,\n",
        "  are described\n",
        "  `here <http://pytorch.org/docs/torch>`.\n",
        "\n",
        "NumPy Bridge\n",
        "------------\n",
        "\n",
        "Converting a Torch Tensor to a NumPy array and vice versa.\n",
        "\n",
        "The Torch Tensor and NumPy array will share their underlying memory\n",
        "locations, and changing one will change the other.\n",
        "\n",
        "Converting a Torch Tensor to a NumPy Array\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNM9z0-sTa65",
        "colab_type": "code",
        "outputId": "6d67d00c-7e65-4bc4-aeb0-0a271cefb61d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UWItQEfTa7C",
        "colab_type": "code",
        "outputId": "2fcaddc5-8f82-44d5-a5c5-96489364fb2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wWueBlTTa7J",
        "colab_type": "text"
      },
      "source": [
        "See how the numpy array changed in value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a28LdUxTa7M",
        "colab_type": "code",
        "outputId": "f291663f-1400-44fe-c57d-614102449f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvX5MJANTa7R",
        "colab_type": "text"
      },
      "source": [
        "Converting NumPy Array to Torch Tensor\n",
        "\n",
        "See how changing the np array changed the Torch Tensor automatically\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbDf2Jl0Ta7S",
        "colab_type": "code",
        "outputId": "bf989805-5981-46b7-9d7b-df6ad6f48586",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_6cjNuPTa7W",
        "colab_type": "text"
      },
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to\n",
        "NumPy and back.\n",
        "\n",
        "CUDA Tensors\n",
        "------------\n",
        "\n",
        "Tensors can be moved onto any device using the ``.to`` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7eviSd2Ta7Y",
        "colab_type": "code",
        "outputId": "06937ff7-d3e5-42e7-82a8-1c9d6d791bc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.6533], device='cuda:0')\n",
            "tensor([0.6533], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv5BZRDuFpdq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9-_5RuNTYBB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Autograd: Automatic Differentiation\n",
        "\n",
        "\n",
        "Central to all neural networks in PyTorch is the ``autograd`` package.\n",
        "Let’s first briefly visit this, and we will then go to training our\n",
        "first neural network.\n",
        "\n",
        "\n",
        "The ``autograd`` package provides automatic differentiation for all operations\n",
        "on Tensors. It is a define-by-run framework, which means that your backprop is\n",
        "defined by how your code is run, and that every single iteration can be\n",
        "different.\n",
        "\n",
        "Let us see this in more simple terms with some examples.\n",
        "\n",
        "**Tensor**\n",
        "\n",
        "\n",
        "``torch.Tensor`` is the central class of the package. If you set its attribute\n",
        "``.requires_grad`` as ``True``, it starts to track all operations on it. When\n",
        "you finish your computation you can call ``.backward()`` and have all the\n",
        "gradients computed automatically. The gradient for this tensor will be\n",
        "accumulated into ``.grad`` attribute.\n",
        "\n",
        "To stop a tensor from tracking history, you can call ``.detach()`` to detach\n",
        "it from the computation history, and to prevent future computation from being\n",
        "tracked.\n",
        "\n",
        "To prevent tracking history (and using memory), you can also wrap the code block\n",
        "in ``with torch.no_grad():``. This can be particularly helpful when evaluating a\n",
        "model because the model may have trainable parameters with `requires_grad=True`,\n",
        "but for which we don't need the gradients.\n",
        "\n",
        "There’s one more class which is very important for autograd\n",
        "implementation - a ``Function``.\n",
        "\n",
        "``Tensor`` and ``Function`` are interconnected and build up an acyclic\n",
        "graph, that encodes a complete history of computation. Each tensor has\n",
        "a ``.grad_fn`` attribute that references a ``Function`` that has created\n",
        "the ``Tensor`` (except for Tensors created by the user - their\n",
        "``grad_fn is None``).\n",
        "\n",
        "If you want to compute the derivatives, you can call ``.backward()`` on\n",
        "a ``Tensor``. If ``Tensor`` is a scalar (i.e. it holds a one element\n",
        "data), you don’t need to specify any arguments to ``backward()``,\n",
        "however if it has more elements, you need to specify a ``gradient``\n",
        "argument that is a tensor of matching shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8-3GwfqTYBP",
        "colab_type": "text"
      },
      "source": [
        "Create a tensor and set requires_grad=True to track computation with it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooWco2LKTYBQ",
        "colab_type": "code",
        "outputId": "fc7bf79b-ccc3-4747-f99d-825ab107008f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS9SAXIZTYBU",
        "colab_type": "text"
      },
      "source": [
        "Do an operation of tensor:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjKZLPH5TYBX",
        "colab_type": "code",
        "outputId": "2e11f2f1-0a63-468d-898c-3b62a3fdbfdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O7Aq6skTYBr",
        "colab_type": "text"
      },
      "source": [
        "``y`` was created as a result of an operation, so it has a ``grad_fn``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_fsbMSQTYBs",
        "colab_type": "code",
        "outputId": "56fe467f-b2f4-4a27-e192-b7c828861a29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7fd7ac3b17f0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o94hOKY_TYBx",
        "colab_type": "text"
      },
      "source": [
        "Do more operations on y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "820gxXTYTYBy",
        "colab_type": "code",
        "outputId": "e6ffbf80-5154-4b9e-cb6c-135300ac854f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut7BAU_ITYB2",
        "colab_type": "text"
      },
      "source": [
        "``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
        "flag in-place. The input flag defaults to ``False`` if not given.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc2QL5f0TYB3",
        "colab_type": "code",
        "outputId": "eb03d860-a714-40ed-bb58-8ea0785e306f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7fd7ac3ed470>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_6m-LW8TYB6",
        "colab_type": "text"
      },
      "source": [
        "Gradients\n",
        "---------\n",
        "Let's backprop now\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4aegGpcTYB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gvyHkmATYCA",
        "colab_type": "text"
      },
      "source": [
        "print gradients d(out)/dx\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbcyrDZBTYCB",
        "colab_type": "code",
        "outputId": "41e789ba-d9bd-4251-bc3b-b28bd61aae50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jegyCPJCTYCE",
        "colab_type": "text"
      },
      "source": [
        "You should have got a matrix of ``4.5``. \n",
        "\n",
        "Remember $out = \\frac{1}{4}\\sum_i z_i$ and\n",
        "$z_i = 3(x_i+2)^2$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwMFBBirTYCk",
        "colab_type": "text"
      },
      "source": [
        "You can also stop autograd from tracking history on Tensors\n",
        "with ``.requires_grad=True`` by wrapping the code block in\n",
        "``with torch.no_grad()``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJpc9geLTYCl",
        "colab_type": "code",
        "outputId": "dae1c1dc-174e-4778-e73c-9c2b59474524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "\tprint((x ** 2).requires_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULuBgoWXTYCw",
        "colab_type": "text"
      },
      "source": [
        "**Read Later:**\n",
        "\n",
        "Documentation of ``autograd`` and ``Function`` is at\n",
        "http://pytorch.org/docs/autograd\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwN4vNsE9rYJ",
        "colab_type": "text"
      },
      "source": [
        "#Part 2: Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-Q6ZNYXZL1R",
        "colab_type": "text"
      },
      "source": [
        "### Load data \n",
        "\n",
        "\n",
        "We will use a dataset of news from radio biobio. Load the data using pandas as pd.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-08T17:49:24.423386Z",
          "start_time": "2019-08-08T17:49:23.409130Z"
        },
        "id": "wZR7-VGzZL1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_json(\n",
        "    'https://github.com/dccuchile/CC6205/releases/download/Data/biobio_clean.bz2',\n",
        "    encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCDuxEJSNx5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset[(dataset.category =='nacional') | (dataset.category =='internacional') | (dataset.category =='economia') | (dataset.category =='sociedad') | (dataset.category =='opinion')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE39JBvEny0r",
        "colab_type": "code",
        "outputId": "4e906eea-e2cc-4bbd-9198-a8f829f86cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 26413 entries, 0 to 26412\n",
            "Data columns (total 10 columns):\n",
            "author                  26411 non-null object\n",
            "author_link             26413 non-null object\n",
            "category                26413 non-null object\n",
            "content                 26413 non-null object\n",
            "embedded_links          26413 non-null object\n",
            "link                    26413 non-null object\n",
            "publication_datetime    26413 non-null int64\n",
            "subcategory             26413 non-null object\n",
            "tags                    26413 non-null object\n",
            "title                   26413 non-null object\n",
            "dtypes: int64(1), object(9)\n",
            "memory usage: 2.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRqm_1K98EvA",
        "colab_type": "code",
        "outputId": "e0ca3834-faaf-4088-86a1-d390a65c234b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>author_link</th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "      <th>embedded_links</th>\n",
              "      <th>link</th>\n",
              "      <th>publication_datetime</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>tags</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yerko Roa</td>\n",
              "      <td>/lista/autores/yroa</td>\n",
              "      <td>nacional</td>\n",
              "      <td>Noticia en Desarrollo  Estamos recopilando m...</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
              "      <td>1565778000000</td>\n",
              "      <td>region-de-valparaiso</td>\n",
              "      <td>[]</td>\n",
              "      <td>Colapsa otro segmento de casa que se derrumbó ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Valentina González</td>\n",
              "      <td>/lista/autores/vgonzalez</td>\n",
              "      <td>nacional</td>\n",
              "      <td>Detectives de la Policía de Investigaciones ...</td>\n",
              "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
              "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
              "      <td>1565771820000</td>\n",
              "      <td>region-metropolitana</td>\n",
              "      <td>[#parricidio, #PDI, #Pudahuel, #Región Metropo...</td>\n",
              "      <td>Policía busca a mujer acusada de matar a su pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Felipe Delgado</td>\n",
              "      <td>/lista/autores/fdelgado</td>\n",
              "      <td>nacional</td>\n",
              "      <td>Dos detenidos fue el saldo de una serie de i...</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
              "      <td>1565772480000</td>\n",
              "      <td>region-metropolitana</td>\n",
              "      <td>[#Incendio, #Liceo de Aplicación, #Región Metr...</td>\n",
              "      <td>Dos detenidos en Liceo de Aplicación: protagon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Matías Vega</td>\n",
              "      <td>/lista/autores/mvega</td>\n",
              "      <td>nacional</td>\n",
              "      <td>La sala del Senado aprobó en general el proy...</td>\n",
              "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
              "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
              "      <td>1565772720000</td>\n",
              "      <td>chile</td>\n",
              "      <td>[#Inmigración, #Inmigrantes, #Ley, #Migración,...</td>\n",
              "      <td>Apoyo transversal: Senado aprueba en general p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Valentina González</td>\n",
              "      <td>/lista/autores/vgonzalez</td>\n",
              "      <td>nacional</td>\n",
              "      <td>La mañana de este miércoles se produjo una e...</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
              "      <td>1565772960000</td>\n",
              "      <td>region-metropolitana</td>\n",
              "      <td>[#Carabineros, #FFEE, #Gases Lacrimógenos, #In...</td>\n",
              "      <td>Evacuación espontánea en Instituto Nacional po...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               author  ...                                              title\n",
              "0           Yerko Roa  ...  Colapsa otro segmento de casa que se derrumbó ...\n",
              "1  Valentina González  ...  Policía busca a mujer acusada de matar a su pa...\n",
              "2      Felipe Delgado  ...  Dos detenidos en Liceo de Aplicación: protagon...\n",
              "3         Matías Vega  ...  Apoyo transversal: Senado aprueba en general p...\n",
              "4  Valentina González  ...  Evacuación espontánea en Instituto Nacional po...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcWsCHUDiNHy",
        "colab_type": "text"
      },
      "source": [
        "Indexing\n",
        "--------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3rTkwvCpRX0",
        "colab_type": "text"
      },
      "source": [
        "The indexer takes as input a list of texts and as params *vocab_size* and *token_mincount*. The params are used in conjunction to build a vocabulary. \n",
        "\n",
        "*   *vocab_size* defines the size of the vocabulary if different to 0.\n",
        "*   *token_mincount* defines the minimun number of appearances of a token in the dataset to be part of the vocabulary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6jM2W3fiLsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Indexer():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def filter_token(self, token):\n",
        "        return (not (token in STOP_WORDS)) and (len(token) >2)\n",
        "        \n",
        "    def fit(self, texts, vocab_size = 0, token_mincount = 0):\n",
        "        tokens = [token for text in texts for token in text.lower().split() if self.filter_token(token)]\n",
        "        \n",
        "        counter_tokens = Counter(tokens)\n",
        "        if (vocab_size > 0):\n",
        "            pairs = counter_tokens.most_common(vocab_size)\n",
        "        else:\n",
        "            pairs = list(counter_tokens.items())\n",
        "\n",
        "        self.vocab = list(set([token for token, count in pairs if count >= token_mincount]))\n",
        "        self.vocab = set([token for token, count in pairs if count >= token_mincount])\n",
        "\n",
        "        self.idx2token = {index:token  for index,token in enumerate(self.vocab)}\n",
        "        self.token2idx = {token:index for index,token in self.idx2token.items()}\n",
        "\n",
        "    \n",
        "\n",
        "    def transform(self, texts):\n",
        "        idxstexts = []\n",
        "        for text in texts:\n",
        "            indexed_text = [self.token2idx[token] for token in text.lower().split() if token in self.vocab]\n",
        "            idxstexts.append(indexed_text)\n",
        "        return idxstexts\n",
        "        \n",
        "    def Item2idx(self, item):\n",
        "        return self.token2idx.get(item, -1)\n",
        "\n",
        "    def Idx2item(self, index):\n",
        "        return self.idx2token.get(index, None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Mqel-Mqnw0",
        "colab_type": "code",
        "outputId": "5931ef01-26a9-4f05-fe43-02e1502c735c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "indexer = Indexer()\n",
        "indexer.fit([\"Estamos en la clase de Natural Language Processing .\",\"La clase de Natural Language Processing es en la sala 105\"],token_mincount = 2)\n",
        "print(indexer.vocab)\n",
        "print(indexer.idx2token)\n",
        "print(indexer.token2idx)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'natural', 'clase', 'processing', 'language'}\n",
            "{0: 'natural', 1: 'clase', 2: 'processing', 3: 'language'}\n",
            "{'natural': 0, 'clase': 1, 'processing': 2, 'language': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBDe10_Hqijz",
        "colab_type": "text"
      },
      "source": [
        "Convert the labels to numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgyV6h2lsD57",
        "colab_type": "code",
        "outputId": "7a491c53-3b46-4f95-9ca8-1951cfb2b0ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "labels = le.fit_transform([\"label5\",\"label3\",\"label4\"])\n",
        "print(le.classes_)\n",
        "print(labels)\n",
        "print(le.inverse_transform([1,2,0]))\n",
        "print(le.transform([\"label5\",\"label4\"]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['label3' 'label4' 'label5']\n",
            "[2 0 1]\n",
            "['label4' 'label5' 'label3']\n",
            "[2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYJ8tmpxaDXG",
        "colab_type": "code",
        "outputId": "1c98e61b-fc6b-406a-d2a2-06de5ed2918c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(list(dataset.category))\n",
        "n_categories = len(le.classes_)\n",
        "n_categories"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cbhmZsXtR_s",
        "colab_type": "text"
      },
      "source": [
        "Split train-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b17sMFE_EB3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(list(dataset.content), y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrU6qwb_tYHQ",
        "colab_type": "text"
      },
      "source": [
        "Build the indexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5AJVpAdN2bF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexer = Indexer()\n",
        "indexer.fit(X_train, vocab_size = 10, token_mincount = 10)\n",
        "vocab_size = len(indexer.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8xhtvcBGzDC",
        "colab_type": "text"
      },
      "source": [
        "Now we have ``category_lines``, a dictionary mapping each category\n",
        "(language) to a list of lines (names). We also kept track of\n",
        "``all_categories`` (just a list of languages) and ``n_categories`` for\n",
        "later reference.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_J5C3xZt3Ki",
        "colab_type": "text"
      },
      "source": [
        "#Classification with Bag-of-Words "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZuuUSv-GzDH",
        "colab_type": "text"
      },
      "source": [
        "##Turning texts into Tensors\n",
        "\n",
        "Now that we have all the texts organized, we need to turn them into\n",
        "Tensors to make any use of them.\n",
        "\n",
        "To represent a single token, we use a \"one-hot vector\" of size\n",
        "``<1 x vocab_size>``. A one-hot vector is filled with 0s except for a 1\n",
        "at index of the current token, e.g. ``\"language\" = <0 1 0 0 0 ...>``.\n",
        "\n",
        "To make a text we join a bunch of those into a tensor\n",
        "``<text_length x 1 x vocab_size>``.\n",
        "\n",
        "That extra 1 dimension is because PyTorch assumes everything is in\n",
        "batches - we're just using a batch size of 1 here.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg-FVJt-GzDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenToIndex(token):\n",
        "    return indexer.Item2idx(token)\n",
        "\n",
        "#Convert a token to a tensor of size <1 x vocab_size>\n",
        "def tokenToTensor(token):\n",
        "    tensor = torch.zeros(1, vocab_size+1)\n",
        "    tensor[0][tokenToIndex(token)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Turn a text into a <text_length x 1 x vocab_size>,\n",
        "# or an array of one-hot token vectors\n",
        "def textToTensor(text):\n",
        "    text_indexed = indexer.transform([text])[0] #Use the indexer to transform the text\n",
        "    tensor = torch.zeros(len(text_indexed), 1, vocab_size+1) #Create the tensor\n",
        "    for li, idx in enumerate(text_indexed): #Fill the tensor with a 1 at the posicion of each token in the vocabulary\n",
        "        tensor[li][0][idx] = 1\n",
        "    return tensor\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-08zVrJUZcQ",
        "colab_type": "text"
      },
      "source": [
        "Lets test the previous functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d9GGtbSUWwc",
        "colab_type": "code",
        "outputId": "e7d83c37-473e-4e44-b33c-7ee5e8f814fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "indexer = Indexer()\n",
        "indexer.fit(X_train, vocab_size = 10, token_mincount = 0)\n",
        "vocab_size = len(indexer.vocab)\n",
        "print(indexer.token2idx)\n",
        "\n",
        "\n",
        "print(tokenToIndex('candidato'))\n",
        "example = textToTensor(\"Donald Trump es el presidente de los Estados Unidos\")\n",
        "print(example)\n",
        "print(example.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'presidente': 0, 'millones': 1, 'personas': 2, 'país': 3, 'trump': 4, 'año': 5, 'unidos': 6, 'años': 7, 'nacional': 8, 'gobierno': 9}\n",
            "-1\n",
            "tensor([[[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]])\n",
            "torch.Size([3, 1, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb8kJ-xoU9AB",
        "colab_type": "text"
      },
      "source": [
        "A little text for torch.mean() that what we will use later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VEiITrXcfWc",
        "colab_type": "code",
        "outputId": "4865ca77-32de-4fb9-8314-4a5a12ea6ec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "m = torch.mean(example,axis=0)\n",
        "print(example.size())\n",
        "print(m)\n",
        "print(m.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 11])\n",
            "tensor([[0.3333, 0.0000, 0.0000, 0.0000, 0.3333, 0.0000, 0.3333, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000]])\n",
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6k_dB7-dVyz",
        "colab_type": "code",
        "outputId": "4738368e-9604-4aaa-9d56-22d40c0e4593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(indexer.idx2token[4])\n",
        "print(indexer.idx2token[8])\n",
        "print(indexer.idx2token[3])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trump\n",
            "nacional\n",
            "país\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G9-PdK_G2yS2"
      },
      "source": [
        "##Creating the Network\n",
        "\n",
        "We will implement a feed-forward neural network. First we average the one-hot representations and pass the average to a fully conneted layer. The output is a softmax with the number of categories.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ve7ELkRr2yS3",
        "colab": {}
      },
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, vocab_size, num_class):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(vocab_size+1, num_class)#A fully connected layer\n",
        "        self.softmax = nn.LogSoftmax()\n",
        "    \n",
        "    def forward(self, text):\n",
        "        text = torch.mean(text,axis=0)#Average the one-hot representations.\n",
        "        output = self.fc(text)\n",
        "        output = self.softmax(output)\n",
        "        return output\n",
        "\n",
        "model = Model(vocab_size, n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jCLtTHXl2yS5"
      },
      "source": [
        "To run this network we need to pass an input (in our case, the\n",
        "Tensor for the token). We'll get back the output (probability of\n",
        "each category).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIX5R5MMGzDR",
        "colab_type": "code",
        "outputId": "2c752d80-6a00-4302-9c6a-990b2d2bfd8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "input_token = tokenToTensor(\"Trump\")\n",
        "print(input_token.size())\n",
        "output = model(input_token)\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n",
            "torch.Size([5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K5_n8lXL2yS9"
      },
      "source": [
        "Now lets test ``textToTensor`` instead of\n",
        "``wordToTensor``. This will be further optimized by\n",
        "pre-computing batches of Tensors.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1wuvCzNGzDU",
        "colab_type": "code",
        "outputId": "cd9946b5-7f90-4308-ab61-a35d0fab9cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "input_text = textToTensor(\"Donald Trump es el presidente de los Estados Unidos\")\n",
        "print(input_text.size())\n",
        "output = model(input_text[0])\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 11])\n",
            "torch.Size([5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "46DAlx2M2yTA"
      },
      "source": [
        "As you can see the output is a ``<1 x n_categories>`` Tensor, where\n",
        "every item is the likelihood of that category (higher is more likely).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CdFzWf4K2yTB"
      },
      "source": [
        "##Training\n",
        "###Preparing for Training\n",
        "\n",
        "Before going into training we should make a few helper functions. The\n",
        "first is to interpret the output of the network, which we know to be a\n",
        "likelihood of each category. We can use ``Tensor.topk`` to get the index\n",
        "of the greatest value:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cb87499d-7f80-4142-b8da-4c3bfb836d29",
        "id": "Pev4tdLv2yTB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return le.inverse_transform([category_i]), category_i\n",
        "\n",
        "print(categoryFromOutput(output))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array(['sociedad'], dtype='<U13'), 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V2JGIQlS2yTE"
      },
      "source": [
        "We will also want a quick way to get a training example (a text and its\n",
        "category):\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6b2e8117-7ee1-4fbd-b1e9-493dafad9285",
        "id": "iLKFoE_v2yTF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "def randomTrainingExampleBoW():\n",
        "    #sample an index\n",
        "    i = random.randint(0, len(y_train) - 1)\n",
        "\n",
        "    #take the category and the text using the index\n",
        "    category = y_train[i]\n",
        "    text = X_train[i]\n",
        "\n",
        "    #make them tensors\n",
        "    category_tensor = torch.tensor([category], dtype=torch.long)\n",
        "    text_tensor = textToTensor(text)\n",
        "    return category, text, category_tensor, text_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    category, text, category_tensor, text_tensor = randomTrainingExampleBoW()\n",
        "    print('category =', category, '/ text =', text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "category = 2 / text =   Los familiares de internos que se encuentran al interior de la Ex Penitenciaría están realizando una manifestación en las afueras del lugar.  El motivo de esta manifestación en por una modificación al decreto ley 321 que tiene relación la libertad condicional, cambio que están calificando como de “ilegal”.  Según denunciaron, los internos mantienen una huelga de hambre hace 14 días para exigir que se vuelva a restaurar los anteriores beneficios para postular a la libertad condicional.  De acuerdo a unos panfletos que están entregando los familiares, indican que “la modificación decreto ley 321 sobre libertad condicional alarga los tiempos de postulación , afectando no solo al preso, sino también a la familia que acompaña y es parte de este proceso de reinserción”.  “Deben respetarse las condiciones de postulación existentes al momento de ser condenados”, añadieron.  Debido a la manifestación, el tránsito estuvo interrumpido en avenida Pedro Montt con Luis Cousiño. Carabineros se encuentra en el lugar, pero no ha intervenido.  Rodrigo Pino | RBB  Rodrigo Pino | RBB  Rodrigo Pino | RBB  Rodrigo Pino | RBB  \n",
            "category = 1 / text =   La tarde del domingo, por causas que se investigan, un incendio arrasó  con el Museo Nacional de Río de Janeiro , uno de los recintos culturales más antiguos del vecino país.  Pese a que no se registraron víctimas fatales, las llamas destruyeron miles de piezas en un edificio que guardaba cerca de 20 millones de elementos para exponer . Los daños son incuantificables.        200 años de historia devorados: las dramáticas imágenes del incendio en museo de Brasil    Entre los tesoros que preservaba el museo había momias egipcias , artefactos grecorromanos, un esqueleto de dinosaurio encontrado en Minas Gerais y los restos de Luzia, el fósil humano más antiguo hallado en Brasil.  La noticia del incendio dio la vuelta al mundo, con videos y fotos de la destrucción, al igual que el lamento de la comunidad educativa y científica ante la destrucción de 200 años de historia .  Pero la cadena O Globo mostró otra parte de la tragedia: la pena de los funcionarios del museo, quienes se acercaron a tratar de ayudar, pero terminaron contemplando cómo lugar de trabajo ardía en llamas.  El registro de video fue compartido a través de la cuenta de Instagram del medio con la reseña “trabajadores intentan entrar en la Quinta de Boa Vista (parque donde se emplaza el recinto) y son sacados por la policía”.   \n",
            "category = 2 / text =   Suspenden preventivamente la instalación de pilotes en las obras del puente Chacao, en la región de Los Lagos. El MOP descartó que represente retrasos en el proyecto.  Como medida de seguridad, los trabajos se encuentran paralizados, a la espera de un documento que formalice la autorización de faenas sin restricciones .  La información entregada por el inspector fiscal de la obra detalla que una grúa impactó con la pilotera durante maniobras de izaje. Esto se debió a que el operador bajó el gancho, pero el cable se enredó.  El seremi de Obras Públicas, James Fry, comentó que el percance no representa retrasos en la obra del futuro viaducto que busca unir a Chiloé con el continente.    La autoridad marítima realizó una visita inspectiva a plataforma Jack Up, sin detectar daño aparente, concluyendo con el consorcio y la empresa Vivargo que la grúa puede ser operada sin restricciones, pero deben entregar formalmente los certificados del servicio técnico o fabricante que autorizaran su uso.  Los resultados de la investigación del incidente se encuentran pendientes.  \n",
            "category = 2 / text =   En recuperación continúan los 80 animales que hace una semana fueron rescatados desde un criadero ilegal en Providencia, en un operativo que reveló las pésimas condiciones en que se mantenían 73 perros, tres gatos y 7 cacatúas ninfa.  Del total, los perros que se encontraban en peores condiciones se mantienen internados en una clínica en convenio con el municipio, mientras que el resto permanece en fundaciones y hogares temporales de particulares.        Internados, en fundaciones y hogares temporales: el estado de perritos rescatados de criadero ilegal    A dos días que se realizara el operativo, la fundación Apla en conjunto con la Defensoría de Derechos Animales presentaron una querella contra el único detenido por el momento, Claudio Javier Parra Hidalgo, que tras ser formalizado por maltrato animal quedó en libertad , con las cautelares de arraigo nacional y firma mensual durante los 120 días decretados como plazo de investigación.  Así, a la persecución del Ministerio Público se suma esta querella, que en el texto detalla que “estos animales se hallaban en condiciones de hacinamiento, siendo encerrados en espacios reducidos, además de encontrarse en un estado físico deteriorado, con cuadros de estrés y deshidratación, sin contar con los cuidados mínimos indispensables para cada una de estas especies”.  El abogado que patrocina esta acción es José Binfa Alvárez, quien en conversación con BioBioChile sostuvo que esperan poder reformalizar al imputado, sumando al menos dos delitos más de acreditarse algunas acusaciones que circulan en torno al imputado.  Esto es el delito de recepctación , ya que muchos de los animales mantenían chip; y ejercicio ilegal de la profesión , puesto que hay acusaciones sobre que se haría pasar por veterinario, llegando incluso a practicar cesáreas.  La alcaldesa Evelyn Matthei aseguró que “este tipo se hacía pasar por veterinario” y señaló que “en general los vecinos tenían algún tipo de agradecimiento hacia él porque le trataba a los perros” por lo que no habían realizado ninguna alerta por el olor.  Sin embargo, al llegar un vecino nuevo al sector, denunció el mal olor proveniente del inmueble y se llevó a cabo el operativo.  Si bien el delito de ejercicio ilegal de la profesión no ha sido aún imputado, de reformalizarlo y ser hallado culpable, las penas van de 61 días a 301 días en su tramo mínimo y de 302 a 540 días en su grado máximo.  Por el delito de receptación, la legislación establece penas desde 61 días, por lo que en la práctica por si solo no conllevaría penas privativas de libertad, sino que podría cumplir con arresto domiciliario o libertad vigilada.  Eso sí, el abogado José Binfa explicó que con la modificación de la Ley de Tenencia Responsable, “el legislador cambia el tipo penal, de causar daño al animal individual”, por lo que estaríamos en presencia del delito reiterado de maltrato por cada animal que se acredite con los informes veterinarios que se afectó su integridad.  Por un delito de maltrato arriesga de 61 días a 3 años , en este caso, si se considera la reiteración, se podría ampliar hasta un grado, llegando a penas de cinco años.  Entre las diligencias solicitadas por los querellantes se encuentra “registrar todo dispositivo electrónico que utilizaba el imputado y analizar los mensajes enviados y recibidos, el tráfico de datos en internet, cuentas virtuales, redes sociales y contactos telefónicos, a fin de determinar si existen más animales afectados u otros intervinientes en calidad de autor, cómplice o encubridor de delitos”.  También se solicitó “empadronar y citar a los vecinos del sector donde ocurrieron los hechos”, quienes de acuerdo a la información del municipio, habrían tenido buena relación con el imputado.   Este artículo describe un proceso judicial en curso  Existe la posibilidad de que los cargos sean desestimados al finalizar la investigación, por lo cual NO se debe considerar al o los imputados como culpables hasta que la Justicia dicte sentencia en su contra. (Artículo 04 del Código Procesal Penal)   \n",
            "category = 2 / text =   La Dirección Meteorológica de Chile emitió una alerta meteorológica de precipitaciones de intensidad normal a moderadas, acompañadas de viento de igual intensidad entre las regiones de Bío Bío y Los Lagos.  El evento meteorológico se podría registrar en las regiones del Bío Bío, La Araucanía, Los Ríos y Los Lagos.  Se estima que las precipitaciones comiencen durante la madrugada de este miércoles 1 de mayo y podrían continuar hasta el jueves 2 de mayo.  Dirección Meteorológica de Chile  En la región de Los Lagos durante la madrugada se podrían registrar precipitaciones con máxima intensidad, extendiéndose a la región de Los Ríos y a la precordillera y cordillera de La Araucanía, continuando para el día jueves 2 de mayo en los sectores de la precordillera y cordillera del tramo sur de la región de Bío Bío.  Otro de los avisos emitidos por la Dirección Meteorológica de Chile, aseguran que estas precipitaciones serán de características líquidas asociadas a una isoterma cero alta, es decir, lluvia donde suele nevar.  Dirección Meteorológica de Chile  A esto se le suma la emisión de aviso de precipitaciones de intensidad normal a moderada, acompañadas de viento desde la región del Maule hasta la región de Aysén.  \n",
            "category = 2 / text =   Un llamado a respetar a los ejemplares de la fauna silvestre realizó el Servicio Agrícola y Ganadero (SAG) Bío Bío, tras el hallazgo en Los Ángeles de un ave fracturada y con un posible proyectil en su interior.  Se trata de un Elanus leucurus , más conocido como “bailarín”, cuyo ejemplar fue encontrado por vecinos del sector El Pedregal de la capital provincial de Bío Bío.  Actualmente el ave se encuentra en el Hospital Clínico Veterinario de la Universidad San Sebastían por la fractura en su ala derecha y la presencia de un objeto metálico, presumiblemente un perdigón , según la radiografía realizada en la clínica veterinaria Pehuén de Los Ángeles.  El director regional del SAG Bío Bío, Iván Ramírez, explicó que es necesario que exista un aviso al servicio cuando ocurran este tipo de situaciones.  “Nosotros queremos que las personas nos ayuden en esto cuando corresponda”, señaló Ramírez, pero también recalcó que cuando se realizan avistamientos de aves que no presentan problemas, las dejen tranquilas.    Además agregó que cuando encuentren una especie herida, existe la posibilidad de entregarlo directamente, pero con los resguardos correspondientes y de esa manera ganar tiempo importante para la recuperación del ejemplar.   Junto con esto, desde el SAG llamaron a respetar y valorar los ejemplares de fauna silvestre , los que tienen un rol fundamental en el equilibrio ecológico del medio ambiente y son benéficos para agricultura.  En el caso del bailarín, también conocido como peuco blanco, es un ave que, de acuerdo a los estudios, basa su dieta principalmente en roedores , cumpliendo un importante papel en la mantención del equilibrio de las poblaciones de esas especies.  Cedida  \n",
            "category = 1 / text =   El Ecuador es un país con una singular relación con el océano: sus aguas territoriales abarcan un área cinco veces superior a su extensión terrestre. En esa amplísima superficie de cerca de un millón y medio de kilómetros cuadrados (un área más grande que el Perú), existen 24 ecosistemas marinos y costeros de los 27 reconocidos a nivel global. En las aguas del Ecuador , además, a mil kilómetros del continente, está uno de los santuarios naturales más importantes del planeta: las islas Galápagos, cuya preservación ha sido fundamental para comprender cómo funciona la vida en nuestro planeta. La existencia del archipiélago ha hecho que la administración, gestión y conservación de los mares ecuatorianos esté regida por la legislación general que abarca la costa continental, y un régimen especial aplicable únicamente a las Galápagos. La conservación de las especies y recursos marinos se ha convertido en un reto para el Estado ecuatoriano, no siempre con resultados satisfactorios. Este reporte revisa ciertas áreas de especial interés, y preocupación, de la situación de los mares del país.  Pesca ilegal y sobreexplotación  En agosto de 2017, el barco carguero chino Fu Yuan Yu Leng 999 fue detenido cuando atravesaba las aguas de la reserva marina del parque nacional Galápagos con 300 toneladas de pesca, entre ellas especies protegidas. Los reportes de prensa iniciales hablaban de más de seis mil tiburones en la embarcación. La reserva marina de Galápagos es una especie de corona imaginaria de 40 millas náuticas que rodea las 330 islas, islotes y rocas que conforman el archipiélago en el que Charles Darwin encontró, a mediados del siglo XIX, las especies que evidenciaban su teoría de la evolución.  Fu Yuan Yu Leng: embarcación china interceptada por la Armada del Ecuador  La detención del barco chino produjo una intensa indignación en el Ecuador. Un año después, el caso ha sido olvidado por un país sumido en discusiones políticas coyunturales. La discusión que se podría haber generado sobre la sobreexplotación de recursos marinos y la pesca ilegal jamás se dio. “La realidad es que en el Ecuador se pesca irregularmente todos los días”, dice Felipe Vallejo, director de la organización no gubernamental Equilibrio Azul. El problema es cotidiano y antiguo. Cuando se creó, en 1988, la reserva marina de Galápagos, para intentar controlar la pesca ilegal los barcos pesqueros chinos “se ponían en el límite para recibir el pepino de mar que era capturado por la gente de Galápagos” dice Santiago Bucaram, economista especializado en recursos costeros. Fue tal la avidez por el pepino de mar, altamente apetecido en Asia, que en apenas tres décadas la especie se puso en riesgo de extinción.  En Galápagos hay 38 especies de pepino de mar, pero solo una se pesca para comercializar. Tal fue la depredación de la especie que en 1992 se prohibió definitivamente su pesca, pero, en la práctica, jamás se detuvo. Desde 2004, el número ha estado por debajo de 13,5 pepinos por cada 100 metros cuadrados . Desde entonces solo ha caído.  Pescadores artesanales de Galápagos, Ecuador. Foto: depositphotos.  El escándalo por el buque chino con las 300 toneladas de pesca ilegal terminó con una declaración triunfalista del entonces Ministro de Ambiente. Pero la pesca ilegal en el Ecuador no viene solo de las flotas industriales —nacionales y extranjeras— que operan en áreas adyacentes a la zona económica exclusiva de Ecuador.Santiago Bucaram, explicaba en 2017 que para las especies altamente migratorias en peligro de extinción, como los tiburones, la actividad pesquera de la flota artesanal palangrera del Ecuador continental era también un riesgo. El palangre es un arte de pesca de alto impacto, que consiste en una línea horizontal de varios kilómetros de las que salen varias líneas de anzuelos.  Un palangre puede tener diez mil anzuelos, que atrapan todo cuanto pasa por ellos. Diseñado para la pesca comercial (picudos, pez espada, atunes, DORADOS), por su dimensión y su incapacidad para distinguir entre especies, también captura, tortugas, lobos y aves marinas, mantarrayas y, por supuesto, tiburones. Felipe Vallejo dice que a los tiburones se los ha pescado tanto que “ los están acabando en el mar continental.incluso en áreas protegidas ya no se los ve. En cambio, uno va a cualquier puerto pesquero y ve tiburones muertos por todos lados”. Según un informe de WWF, los recursos sobreexplotados en el Ecuador son peces pelágicos pequeños —como la sardina o pinchagua, la macarela y el chuhueco—, ciertas especies de peces demersales, de lento crecimiento como los pargos, los meros y las chernas la concha prieta y el cangrejo azul. El tiburón ocupa un lugar especial en la sobreexplotación, porque su pesca en el Ecuador solo está permitida si es incidental. Es decir, si se los atrapa por accidente.  Lobo de mar lastimado por anzuelo. Foto: Carolina Larrea.  La flota artesanal continental ecuatoriana está compuesta por más de 45 mil embarcaciones. La mayoría zarpa del puerto de Manta hacia las Galápagos. La definición de ‘pesca incidental’ fue hecha en un decreto ejecutivo firmado por el entonces presidente Rafael Correa (en julio de 2007). Según explica Bucaram, es arbitraria porque “quienes deciden la condición de incidentalidad de la captura son los mismos pescadores”. De acuerdo a un estudio de 2015 , se capturan, por los menos, un cuarto de millón de tiburones cada año. Según Bucaram, “esta cifra hace dudar que la pesca de tiburón, hecha por la flota artesanal ecuatoriana, sea incidental. Por el contrario, más parece una pesca dirigida: el objetivo no declarado de dicha flota”. Bucaram explica en su ensayo que una porción sustancial de la captura de estos tiburones se obtiene en el borde de la reserva marina de Galápagos. “ Las embarcaciones artesanales ecuatorianas no están obligadas a llevar sistemas satelitales de rastreo , por lo que potencialmente podrían haber ingresado, desde el continente, sin ser detectadas a las aguas de la reserva marina para pescar.” Una fuente que pidió que su identidad se mantenga en reserva dijo a Mongabay Latam que la pesca dirigida de tiburones, tanto en el continente como en las Galápagos, es un secreto a voces: “Los pescadores dicen ‘ah ponemos esa arte de pesca -el palangre- porque es la buena para tiburones’. Lo hacen de forma totalmente abierta, y es irónico porque también es super oculto: el gobierno insiste en que no hay pesquería de tiburón”.  Tiburones capturados en el malecón de Puerto López, Ecuador. Foto: Rocío Muñoz  La falta de estadísticas es un problema grave en el Ecuador, país que, según la Organización de Naciones Unidas para la Alimentación y la Agricultura (FAO), es uno de los 25 en el mundo con mayor producción de pesca en el mar . De acuerdo al organismo, la producción ecuatoriana pasó de 643.176 toneladas en 2015 a 715.357 el año siguiente: un incremento de más del 11%. Según la Cámara Nacional de Pesquería —que aglutina a la mayor parte de la flota atunera ecuatoriana y de pelágicos pequeños, a industrias de producción de pescado fresco, congelado, en conservas y harineras— entre 2012 y 2017, la pesca aportó anualmente al Ecuador alrededor de 1.500 millones de dólares en exportaciones. . Además, dice el gremio, la industria emplea directamente a alrededor de 108 mil personas. La industria formal que es, en términos económicos, altamente productiva, tiene un costo en conservación: es tan grande que el Estado no alcanza a monitorear y vigilar la actividad pesquera en el Ecuador —lo que permite que la pesca ilegal prospere, explica el exfuncionario de pesca.  Un exfuncionario del Ministerio de Acuicultura y Pesca dice a Mongabay Latam que en el Ecuador no hay una medida ni cuantificación oficial de cuánto suma la pesca ilegal en el país. Hay “hay mucha ‘cifra negra’”, dice el exfuncionario. En el Ecuador hay cerca de 300 inspectores de pesca, pero “no todos están cumpliendo su labor. Es algo que pasa en todo el mundo, si el fiscalizador no hace bien su trabajo, la cifra reportada no es verdadera.”  La información de cuánto produce la pesca ilegal, en términos económicos, es solo referencial. El precio del kilo de la aleta de tiburón es de 650 dólares . Si el barco chino, que fue detenido en 2017 en la reserva marina de Galápagos, llevaba 300 toneladas de tiburón y la aleta es el 5% del peso de un tiburón promedio, podría decirse que el carguero llevaba unas 15 toneladas de aletas: potencialmente casi diez millones de dólares solo en esa captura. Vallejo considera que a la hora de determinar cuánto le cuesta al Ecuador la pesca ilegal, es necesario considerar el dinero público invertido en producción pesquera. “Al igual que en otros países, toda esta sobrepesca es subsidiada, si no, la pesquería no sería negocio”. Por ejemplo, en el Ecuador, los combustibles que utilizan los pescadores en sus embarcaciones están subsidiados. “La pesca recibe varios tipos de subsidios y apoyos que, sumados, dan muchos millones de dólares al año”. Es así como Vallejos sentencia que “vamos a terminar con las especies marinas con plata pública” dice.  Más de 9.500 toneladas de plásticos vertidos al mar  La contaminación por plástico es uno de los mayores desafíos ambientales en los océanos del planeta. Cada año, se vierten en los mares del mundo hasta 13 millones de toneladas de este material. La producción de plástico, según el programa para el medioambiente de las Naciones Unidas, seguirá su curva ascendente: de casi cero en la década de 1950 se ha disparado hasta 262 millones de toneladas en 2013. Para 2050, se estima que la producción alcanzará las 1.800 toneladas.  Estudio señala que casi la mitad de las especies de rayas mobula están amenazadas por los microplásticos. Foto: Elitza Germanov / Fundación Megafauna Marina.  Según cifras de gobierno , en las áreas costeras del Ecuador viven cerca de 2 millones de personas: el 13% de la población total. De las más de 4.100.000 toneladas de desechos que se producen en el país anualmente, el 11% corresponde a plástico. Es decir, 451 mil toneladas. Aunque no existen cifras claras sobre qué porcentaje de ese total llega hasta el mar ecuatoriano, el informe Basura Marina del programa para el medioambiente de las Naciones Unidas, estima que más de 9.500 toneladas de plásticos vierte el país al océano pacífico. El equivalente al peso de 48 ballenas azules, el mamífero más grande del planeta.  A pesar de ello, un informe de las Naciones Unidas señala que “el país ha impulsado una serie de medidas para fomentar el “desarrollo limpio” y abordar el problema de la contaminación desde tierra firme”.  En efecto, el Ecuador es parte de la campaña Mares Limpios de la ONU , que busca que “los gobiernos, las empresas y la sociedad civil se comprometan para reducir drásticamente la contaminación por plásticos en los océanos”.  Durante las jornadas de limpieza que se han realizado en Colombia se han sacado toneladas de llantas y plásticos. Foto: Comisión Colombiana del Océano (CCO).  En 2014, el Consejo de Gobierno del Régimen Especial de Galápagos prohibió el comercio, distribución, expendio y entrega de bolsas plásticas desechables. Según una nota del programa de Ambiente de las Naciones Unidas, un programa de gestión de residuos en la isla de Santa Cruz, la más poblada de las Galápagos, ha logrado hasta un 45% de recuperación de residuos sólidos reciclables, el porcentaje más alto en Ecuador.  La investigadora Kate Huyvaert, de la Universidad de Colorado, señala en una investigación que la presencia de plástico en los cadáveres de pichones de albatros muertos en la isla Española, en las Galápagos, era de 0% en 2007. Cuatro años después, había subido a 20% y en 2016, encontró plástico en cuatro de cada diez casos. Un reporte de la organización no gubernamental Mingas por el mar , dice que entre el 25 de marzo y el 30 de junio de 2018 recogió más de 4 mil kilos de plásticos en jornadas de limpieza comunitaria en 26 playas de 2 localidades del Ecuador. De esas cuatro toneladas, el 17% eran insumos de pesca abandonados. El 83% restante, era basura producida en centros urbanos. De ese total, apenas el 16% era material reciclable.  Estado de conservación  Felipe Vallejo, de la fundación Equilibrio Azul, dice que la situación de los océanos en el Ecuador es más precaria que nunca: “contaminación, impacto pesquero, cambio climático, no hay datos completos como en otros países”. Vallejo señala que “hay mucha gente valiosa en el Ministerio del Ambiente y en las áreas marinas protegidas, a la que le interesa de verdad preservar los mares ecuatorianos, pero el principal problema es la falta de recursos”.  Según Felipe Vallejo, las declaratorias de áreas protegidas no siempre son eficientes: “Muchas de estas áreas marinas son áreas protegidas de papel: están en un decreto, pero la realidad es que no hay ningún tipo de protección.. Si decretamos áreas protegidas pero no las dotamos de recursos, en realidad no cuidamos al mar”  Tortuga marina en Galápagos, Ecuador. Foto: depositphotos.  En el parque nacional Machalilla, al igual que en la reserva marina de Galápagos, dice un funcionario del Ministerio de Pesca que prefiere el anonimato, “se pesca todos los días, aunque se supone que está prohibido”. Ni siquiera Galápagos, que es la que mayores recursos tienes, alcanza a ser debidamente controlada: la dirección del parque nacional Galápagos tiene cuarenta funcionarios en tareas de control y patrullaje, dos lanchas oceánicas, cinco lanchas costeras rápidas, dos botes inflables para bahía y un hidroavión. Es muy difícil abarcar el mar que debe controlar con tan limitados recursos.  La Red de Áreas Marinas y Costeras Protegidas de Ecuador Continental (Esmeraldas, Manabí, Guayas, El Oro y Santa Elena), actualmente está conformada por 19 áreas en las 5 provincias costeras del Ecuador continental y abarcan una superficie de 679.295 hectáreas. A esas áreas se suman los dos parques nacionales costeros: Galápagos y su reserva marina, y el parque nacional Machalilla.  El país es parte del Corredor Marino del Pacífico Este Tropical (CMAR), una iniciativa regional liderada por los gobiernos de Costa Rica, Panamá, Colombia y Ecuador. “La iniciativa busca la adecuada gestión de la biodiversidad y los recursos marinos y costeros, mediante un manejo ecosistémico y establecimiento de estrategias regionales gubernamentales conjuntas”, explica el Ministerio de Defensa. “Esta decisión se implementa a través de áreas núcleo, en nuestro país, son las Islas Galápagos”. El CMAR tiene entre sus propósitos, propiciar el manejo y la conservación de los recursos marinos, mejorar y consolidar la gestión de las Áreas Marinas Protegidas que conforman el corredor, establecer un marco regional que facilite el desarrollo y le gestión integral del corredor, compatible con las políticas y legislaciones nacionales, entre otros.  Reserva Nacional Machalilla, Ecuador. Foto: depositphotos.  Según el Ministerio de Ambiente, a través de la Subsecretaría de Gestión Marina y Costera, desarrolla “algunos proyectos de cooperación alineados a las necesidades de esta zona, con fondos del GEF, de la BMZ; organismos intergubernamentales y cooperación técnica como FAO, PNUD, COI UNESCO, GIZ y organizaciones no gubernamentales, como WWF, CI Ecuador”. Además, dice el Ministerio, una de las prioridades del Ecuador ha sido la preservación del ecosistema manglar, “a través de los Acuerdos de Uso Sustentable y Custodia del Manglar entregados a usuarios tradicionales y ancestrales de este ecosistema, promueve la conservación y aprovechamiento sostenible de sus recursos”. Según el organismo, se habrían entregado 52 acuerdos que abarcan una superficie de más de 68 mil hectáreas de manglar.  La amenaza de los derrames de petróleo  El Ecuador es un país petrolero. A diferencia de la idea generalizada, el primer hallazgo de crudo no fue en la Amazonía, sino en el pequeño pueblo pesquero de Ancón, donde en 1911 una compañía británica explotó los primeros pozos petroleros del país. Más de un siglo después, el mar del Ecuador sigue repleto de petróleo y gas licuado. Junto al de Ancón, hay 10 campos petroleros. Al sur, cerca del refugio de vida silvestre isla Santa Clara, está el campo Amistad.  La península de Santa Elena, el punto más saliente del país hacia el Pacífico, está divida en bloques petroleros marcados desde la B01 a la B05. Son los únicos bloques petroleros ecuatorianos que no están en la Amazonía, donde existen 82 más.  Galápagos. Vista desde la playa de Cerro Brujo. Foto: Rhett A. Butler.  El derrame de petróleo es una amenaza constante en el océano ecuatoriano. En 2008, la rotura de una tubería en la refinería de Santa Elena, contaminó casi un kilómetro cuadrado en aguas de la costa frente al balneario de La Libertad y cerca de Puerto Lucía. En los últimos 5 años ha habido al menos un derrame de petróleo considerable en Esmeraldas. El más reciente, fue en la playa de Las Palmas, donde se derramaron 20 barriles de crudo liviano. La zona, muy cercana a la frontera con Colombia, vive en un estado de abandono y desidia hace varias décadas, registrando los números más altos pobreza, analfabetismo y homicidios por cada cien mil habitantes.  Proyectos de ley detenidos en la Asamblea Nacional  Las medidas de conservación y protección de los espacios marinos en el Ecuador están plasmadas en una serie de cuerpos legales. La norma suprema que rige el cuidado de los oceanos en el país es la Constitución de la República, “a través de los artículos relacionados a los derechos de la naturaleza, ecosistemas frágiles y conservación del patrimonio natural del Estado”, según el Ministerio de Ambiente.  Además, a nivel internacional, el Ecuador está adherido a algunos convenios Internacionales como la Organización Marítima Internacional, Convención de las Naciones Unidas sobre el Derecho del Mar (CONVEMAR), el convenio Internacional para Prevenir la Contaminación por los Buques (MARPOL). “El país, en el marco de la Agenda 2030 y del Objetivo de Desarrollo Sostenible No. 14, presentó 14 compromisos voluntarios nacionales que contribuirán a la protección del océano” dice el Ministerio de Ambiente.  Vista aérea de Punta Cormorant, en la isla Floreana, hábitat histórico de la Pseudalsophis biserialis biserialis. Foto cortesía de la Dirección del Parque Nacional Galápagos  La Ley de Pesca, que data de 1974, es quizá la pieza de legislación que mayor incidencia tenga en la salud de los océanos en el Ecuador, por la gran dimensión de sus flotas pesqueras, tanto industrial, como artesanal.  En la Asamblea Nacional del Ecuador (el poder legislativo) reposan tres proyectos de reforma a esta ley, sin que ninguno haya prosperado. El Ministerio de Acuacultura y Pesca redactó, en diciembre de 2017, un proyecto de ley para sustituir completamente a la actualmente vigente. Santiago Bucaram, economista experto en recursos naturales, lo calificó de “un buen comienzo” que necesitaba “algunas mejoras”. Sin embargo, hasta septiembre de 2018, el proyecto de ley ni siquiera había sido presentado ante la Asamblea Nacional.  Sí, como dice Vallejo, el estado de los mares es el peor posible, y la falta de recursos es la constante, las declaraciones rimbombantes y sobreentusiastas del gobierno y los ministros de ambiente de turno no serán sino solo promesas de papel.  Por José María León Cabrera Este artículo fue publicado originalmente en Mongabay Latam  Respuesta Embajada de Ecuador en Chile  A raíz de la publicación de este artículo, la Embajada de Ecuador en Chile derivó a nuestro medio una nota en la cual aclara algunos de los puntos consignados, o rebate las cifras entregadas.  Como parte de su derecho a réplica, BioBioChile comparte íntegramente la carta derivada por el embajador, señor Homero Arellano Lascano .   Nota Embajada de Ecuador sobre artículo pesca ilegal by BioBioChile on Scribd   \n",
            "category = 1 / text =   Los rescatistas buscaban este martes a las decenas de personas que podrían haber quedado atrapadas en un edificio que se derrumbó la víspera cerca de Manila tras un potente sismo que dejó al menos 11 muertos, según un nuevo balance.  El balance anterior, anunciado la noche del lunes, daba cuenta de cinco muertos debido al temblor, de magnitud 6,3 según el Servicio Geológico de Estados Unidos (USGS).  El sismo, que provocó importantes daños en el aeropuerto internacional Clark, el aeródromo secundario de la capital, hizo temblar también los inmuebles de Manila, provocando escenas de pánico.  Este terremoto, que es el más fuerte que sufre la capital filipina en años, se produjo a las 17:11 locales (05:11 de Chile) a 40 km de profundidad, con epicentro en Castillejos, en la provincia de Zambales, unos 100 km al noreste de Manila.  Pero fue en la provincia vecina de Pampanga donde se registraron los daños materiales de mayor envergadura y donde murieron 11 personas, según las autoridades filipinas. También resultaron heridas decenas de personas en todo el archipiélago y el balance podría aumentar.  En la zona se desplegaron equipos de socorristas para evaluar los desperfectos, así como en localidades aisladas privadas de electricidad y de medios de comunicación.  En Porac, en la isla de Luzón, se libraba una carrera contrarreloj para retirar las ruinas de un edificio de cuatro pisos derrumbado en el que podría haber una treintena de personas atrapadas.  “Se oye al menos a una persona aún viva”, declaró a los periodistas Lilia Pineda, gobernadora de Pampanga. “Está atrapada bajo losas de cemento”  El temblor también dañó iglesias de hace varios siglos que en los últimos días habían recibido a una multitud de fieles para las misas de Semana Santa, en un archipiélago en el que el 80% de la población es católica.  Filipinas se encuentra en el “Cinturón de Fuego” del Pacífico, donde la colisión entre placas tectónicas suele provocar sismos y una importante actividad volcánica.  El sismo más mortífero en el archipiélago desde que se miden las magnitudes se produjo en 1976. Murieron miles de personas, según algunos cálculos hasta 8.000.  \n",
            "category = 1 / text =   Texas ejecutó a un hombre el martes que, junto con otros seis conocidos como los “Siete de Texas”, mató a un oficial de policía  en el año 2000, antes de ser arrestado gracias en parte al programa de televisión “America’s Most Wanted (Los más buscados de Estados Unidos)”.  Joseph Garcia, de 47 años, fue ejecutado por inyección letal y declarado muerto a las 18:43 hora local (21:43 de Chile) en Huntsville, anunciaron las autoridades texanas.  Condenado a 50 años de prisión por matar a un amigo durante una pelea, Garcia y otros seis presos participaron en una fuga de la prisión de alta seguridad de Connally, en el sur de Texas.  Los hombres atacaron a los guardias para conseguir sus uniformes y obligaron a otro a abrir la puerta. Uno de los padres de los presos les esperaba con un automóvil fuera de la prisión.  Para financiar su huida, los “Siete de Texas” saquearon negocios minoristas, y en la víspera de Navidad, atacaron una tienda de artículos deportivos en un suburbio de Dallas.  Cuando los hombres huyeron de la escena, mataron a Aubrey Hawkins, un joven oficial de policía que acudió a la zona para dar refuerzo , y que fue acribillado.  Las autoridades lanzaron una persecución, y ofrecieron una recompensa de 100.000 dólares, que llegó a aumentar a 500.000, para obtener información sobre la pandilla.  Después de la emisión de un episodio de “America’s Most Wanted”, un programa popular dedicado a la búsqueda de delincuentes peligrosos, varias personas informaron que se habían cruzado con los fugitivos.  Seis semanas después de su fuga, los hombres fueron detenidos en Colorado y uno de ellos se suicidó durante el arresto.  Los otros seis fueron declarados culpables del asesinato del oficial y condenados a muerte. Tres ya fueron ejecutados y dos más permanecen en el corredor de la muerte.  Los abogados de Garcia presentaron, sin éxito, una apelación de última hora ante el Tribunal Supremo para suspender la ejecución, argumentando que no fue el autor de los disparos fatales.  \n",
            "category = 2 / text =   En construcción se encuentran las jaulas para atrapar a los lobos marinos que dejaron más de 300 cisnes de cuello negro muertos en el Santuario de la Naturaleza Carlos Anwandter de Los Ríos, confirmó la seremi de Agricultura Moira Henzi.  Se trata de una parte de las Balsas-Jaulas propuestas por una mesa multisectorial convocada por el Gobierno, para atrapar y posteriormente trasladar al zoológico Buin Zoo , a los lobos marinos que el año pasado atacaron y mataron a los Cisnes de Cuello Negro en el Río Cruces.        Sernapesca ratifica traslado de lobos marinos que atacaron a cisnes de cuello negro en Valdivia    La seremi de Agricultura de Los Ríos, Moira Henzi, que coordina dicha mesa, confirmó a Radio Bío Bío que la Municipalidad de Valdivia hace una semana construye las jaulas, tras la donación de los elementos para ello, realizada por un anónimo.    La autoridad descartó que se hayan avistado a los lobos marinos juveniles que efectuaron los ataques a las aves protegidas, que recordemos se alejaron de la zona por estar en etapa de reproducción.  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qez2B5MC2yTH"
      },
      "source": [
        "Training the Network\n",
        "--------------------\n",
        "\n",
        "Now all it takes to train this network is show it a bunch of examples,\n",
        "have it make guesses, and tell it if it's wrong.\n",
        "\n",
        "For the loss function ``nn.NLLLoss`` is appropriate, since the last\n",
        "layer of the model is ``nn.LogSoftmax``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJyUzAC9X1LQ",
        "colab_type": "text"
      },
      "source": [
        "Lets split the dataset again and build the indexer with a bigger vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qxCSzh3i2yTL",
        "colab": {}
      },
      "source": [
        "indexer = Indexer()\n",
        "indexer.fit(X_train, vocab_size = 1000)\n",
        "vocab_size = len(indexer.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bv4V8Q8b2yTN",
        "colab": {}
      },
      "source": [
        "model = Model(vocab_size, n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "13UlOqwh2yTQ",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aAn_YKzt2yTS"
      },
      "source": [
        "Each loop of training will:\n",
        "\n",
        "-  Create input and target tensors\n",
        "-  Read each text in \n",
        "-  Compare final output to target\n",
        "-  Back-propagate\n",
        "-  Return the output and loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E9cnE4f52yTT",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
        "\n",
        "def train(category_tensor, text_tensor):\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    output = model(text_tensor)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    # Add parameters' gradients to their values, multiplied by learning rate\n",
        "    for p in model.parameters():\n",
        "        p.data.add_(-learning_rate*p.grad.data)\n",
        "    return output, loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "afDLUNvU2yTV"
      },
      "source": [
        "Now we just have to run that with a bunch of examples. Since the\n",
        "``train`` function returns both the output and loss we can print its\n",
        "guesses and also keep track of loss for plotting. We print only every ``print_every`` examples, and take an\n",
        "average of the loss.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f3ufQwaS2yTW",
        "colab": {}
      },
      "source": [
        "\n",
        "import time\n",
        "import math\n",
        "def loop_training(batch = 1, example_generator=randomTrainingExampleBoW):\n",
        "    plot_every = 1000//batch\n",
        "\n",
        "    n_iters = plot_every*10\n",
        "    \n",
        "    # Keep track of losses for plotting\n",
        "    current_loss = 0\n",
        "    all_losses = []\n",
        "\n",
        "    def timeSince(since):\n",
        "        now = time.time()\n",
        "        s = now - since\n",
        "        m = math.floor(s / 60)\n",
        "        s -= m * 60\n",
        "        return '%dm %ds' % (m, s)\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        if batch>1:\n",
        "            category, text, category_tensor, text_tensor = example_generator(batch)\n",
        "        else:\n",
        "            category, text, category_tensor, text_tensor = example_generator()\n",
        "        output, loss = train(category_tensor, text_tensor)\n",
        "        current_loss += loss\n",
        "\n",
        "        \n",
        "        # Add current loss avg to list of losses\n",
        "        if iter % plot_every == 0:\n",
        "            all_losses.append(current_loss / plot_every)\n",
        "            current_loss = 0\n",
        "    return all_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W92qLG9UHqqJ",
        "colab_type": "code",
        "outputId": "404f0e43-dad7-4f59-a000-4b8efa2fd53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "%%time\n",
        "all_losses = loop_training(batch = 1, example_generator=randomTrainingExampleBoW)\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 13.7 s, sys: 595 ms, total: 14.3 s\n",
            "Wall time: 14.5 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwWDJSIMaZ2B",
        "colab_type": "text"
      },
      "source": [
        "##Batch processing\n",
        "Until now we trained with one example at each step. One of the reason of success of neural networks is parallel processing which is used best with batch processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnCQLMy-cQFE",
        "colab_type": "text"
      },
      "source": [
        "This function creates a batch of examples with size ``<text_length x batch_size x vocab_size>``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ia3vJg8G2yTf",
        "colab": {}
      },
      "source": [
        "def randomTrainingBatchBoW(batch_size):\n",
        "    categories = []\n",
        "    texts = []\n",
        "\n",
        "    #Select batch_size examples from (X_train,y_train)\n",
        "    for _ in range(batch_size):\n",
        "        i = random.randint(0, len(y_train) - 1)\n",
        "        category = y_train[i]\n",
        "        categories.append(category)\n",
        "        \n",
        "        text = X_train[i]\n",
        "        texts.append(text)\n",
        "\n",
        "    #Create the category_tensor from the categories sampled\n",
        "    category_tensor = torch.tensor(categories, dtype=torch.long)\n",
        "    \n",
        "    #Index each text (indexer.transform() takes as input a list of texts)\n",
        "    indexed_texts = indexer.transform(texts)\n",
        "\n",
        "    #Find the longest sequence in the batch\n",
        "    max_length = max([len(text) for text in indexed_texts])\n",
        "    \n",
        "    #Add padding the make all the sequence as long as the longest.\n",
        "    indexed_texts = [text+[vocab_size]*(max_length-len(text)) for text in indexed_texts]\n",
        "\n",
        "    #Create the tensor\n",
        "    text_tensor = torch.zeros([len(indexed_texts[0]), batch_size, vocab_size+1])\n",
        "\n",
        "    #Add the one to each position\n",
        "    for i,indexed_text in enumerate(indexed_texts):\n",
        "        for j,idx in enumerate(indexed_text):\n",
        "            text_tensor[j][i][idx] = 1\n",
        "    \n",
        "    return categories, indexed_texts, category_tensor, text_tensor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPEiUujyef0G",
        "colab_type": "text"
      },
      "source": [
        "###Lets train now using batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp58lhLjQPsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(vocab_size, n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FsjQr6QAUbL",
        "colab_type": "code",
        "outputId": "286fa576-0d17-4075-c842-254d1e00e3ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "%%time\n",
        "all_losses = loop_training(batch=10, example_generator=randomTrainingBatchBoW)\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15.6 s, sys: 94.2 ms, total: 15.7 s\n",
            "Wall time: 15.7 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZD9Pih0r6SwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBICZPH127DJ",
        "colab_type": "text"
      },
      "source": [
        "Classification with embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5roDdkg5GzDM",
        "colab_type": "text"
      },
      "source": [
        "##Creating the Network\n",
        "This network is veru similar to the previous one. The only difference is that we add an embedding layer as first step. Then we do the same processing, fully connected and softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnxH6Ds7GzDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size+1, embed_dim)#The embedding layer\n",
        "        self.fc = nn.Linear(embed_dim, num_class)#A fully connected layer\n",
        "        self.softmax = nn.LogSoftmax()\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        embedded = torch.mean(embedded,axis=0)#Average the embeddings representation.\n",
        "        output = self.fc(embedded)\n",
        "        output = self.softmax(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "        \n",
        "n_hidden = 128\n",
        "model = Model(vocab_size, n_hidden, n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rohxCw5WGzDZ",
        "colab_type": "text"
      },
      "source": [
        "###Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RM_ansYBjn7b",
        "outputId": "812a9154-c279-45f4-8955-dbec17268277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "def randomTrainingExampleEmb():\n",
        "    i = random.randint(0, len(y_train) - 1)\n",
        "    category = y_train[i]\n",
        "\n",
        "    text = X_train[i]\n",
        "\n",
        "    category_tensor = torch.tensor([category], dtype=torch.long)\n",
        "    \n",
        "    indexed_text = indexer.transform([text])[0]\n",
        "    #Here it is different to the one that we used for BoW\n",
        "    text_tensor = torch.zeros([len(indexed_text),1],dtype=torch.long)#Before it was torch.zeros(len(text_indexed), 1, vocab_size+1)\n",
        "\n",
        "    #Here it is different to the one that we used for BoW\n",
        "    for i,idx in enumerate(indexed_text):\n",
        "        text_tensor[i][0] = idx #Before it was tensor[li][0][idx] = 1\n",
        "    \n",
        "    return category, text, category_tensor, text_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    category, text, category_tensor, text_tensor = randomTrainingExampleEmb()\n",
        "    print(text_tensor.size())\n",
        "    print('category =', category, '/ text =', text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([35, 1])\n",
            "category = 1 / text =   La jornada de este viernes dos tiroteos paralelos afectaron mezquitas en la ciudad de Christchurch en Nueva Zelanda.  Según la prensa local, al menos seis personas murieron , mientras que una gran cantidad quedó con heridas. Cifra que podría aumentar en el transcurso de la jornada        Tiroteos paralelos en dos mezquitas de Nueva Zelanda dejan gran cantidad de muertos    La policía neozelandesa encontró artefactos explosivos luego de los tiroteos señalaron medios internacionales.  Se trataría de bombas caseras que fueron localizadas en los automóviles en los que se movilizaban los atacantes, las que posteriormente fueron desactivadas por personal especializado.  Al menos cuatro personas se encuentran detenidas por los tiroteos.  “Cuatro personas están bajo custodia, tres hombres y una mujer”, dijo el comisionado de policía Mike Bush, quien confirmó el hallazgo de los explosivos.        Policía neozelandesa anuncia captura de cuatro sospechosos por tiroteos en mezquitas    La primera ministra del país, Jacinda Ardern, señaló que “resulta claro que este es uno de los días más oscuros de Nueva Zelanda. Claramente, lo que ha ocurrido aquí fue un acto de violencia extraordinario y sin precedentes”.  El autor de la masacre sería Brenton Tarrant, un australiano de 28 años , el que transmitió vía Facebook el ataque. Autoridades del país solicitaron no compartir el registro, ya que buscan eliminarlo de todas las plataformas.  \n",
            "torch.Size([30, 1])\n",
            "category = 1 / text =   El presidente de Argentina, Mauricio Macri , se emocionó hasta las lágrimas en la gala del G20 , cita de las economías más grandes del mundo que por primera vez se realiza en un país de Sudamérica.  El evento tuvo lugar en el Teatro Colón de Buenos Aires y su quiebre ocurrió tras el fin de uno de los espectáculos con los cuales la organización homenajeó a los jefes de Estado presentes en el recinto.  Los artistas se acercaron al borde del escenario para recibir un cerrado aplauso por parte de los asistentes, entre ellos Vladimir Putin, Angela Merkel y Donald Trump; cuando el mandatario trasandino se vio abiertamente emocionado.  El presidente Sebastián Piñera también presenció el momento. Pese a que Chile no es parte del G20, Macri lo invitó a participar de la cumbre, tal como Felipe Calderón lo hiciera en 2012.  Su esposa , Juliana Awada , lo consoló ; y la canciller alemana fue una de las más entusiasmadas con la espontánea manifestación.  “¡Argentina, Argentina!” se oyó gritar a muchos al interior del Colón, Macri uno de ellos.  AHORA – El llanto y la emoción de Mauricio Macri. El aplauso de pie de los líderes del G20  pic.twitter.com/MhQysQl6Nv  — TN – Todo Noticias (@todonoticias) 30 de noviembre de 2018   \n",
            "torch.Size([63, 1])\n",
            "category = 2 / text =   Ante la ministra Romy Rutherford declaró el teniente coronel del Ejército Cristóbal Butti López , cercano al ex comandante en jefe Humberto Oviedo, que se dedicaba a administrar el domicilio de su superior en Lo Curro, Vitacura.  Pese a que lideró el área de tecnología en la Escuela Militar, pasó por Inteligencia y estuvo destinado en la Antártica, Oviedo lo nombró “oficial de órdenes”.        Someten a proceso a general (r) Oviedo por malversación de caudales públicos de $4.500 millones    Según constató La Tercera , las asignaciones de Butti iban desde mantener la casa a la compra de regalos para el Alto Mando , según la indagatoria, con gastos reservados, puesto que recibía dinero en efectivo sin respaldo del jefe de Finanzas de la Comandancia en Jefe.  “Vásquez, por orden del comandante en jefe Oviedo, le entregaba la suma de $6 millones mensuales. Afirma que toda la asignación de recursos era determinada por el comandante en jefe”, se estableció en el procesamiento a Oviedo, añadiendo que el monto fue aumentando, llegando a los $25 millones en algunas ocasiones.  Diferentes regalos  Además de estar encargado de todas las compras de la casa, que coordinada con la esposa de Oviedo, el medio detalló que existían tres tipos de regalos: Clase A,B y C, los que fluctuaban entre los 140 mil y 60 mil pesos.  Asimismo, se estableció que los dulces eran fundamentales, puesto que destinaba $21 millones al año para el repostero de la casa y, además, contaba con un stock de chocolates .  “Compraban en La Fete, Mulier o Leonidas. Expone que se regalaban cuando el comandante en jefe Oviedo o su señora iban a alguna parte (…) Se compraban entre seis a ocho cajas en la semana, cuyos valores fluctuaban entre los $ 10 a $ 18 mil, y otras de unos 400 gramos. Se gastaban aproximadamente unos $150 mil a la semana en chocolates” , se detalló en el escrito.  Posteriormente, Butti también se hizo cargo de comprar los regalos de Navidad .  En ese sentido, declaró ante Rutherford que en 2015 gastó 8 millones de pesos, comprando 70 regalos para el Alto Mando.  Los años siguientes hubo gastos similares para la festividad. Por ejemplo, compró 20 lápices de 350 mil pesos cada uno.  La Tercera añadió que Butti declaró que le daba “vergüenza” pagar con efectivo, por lo que a veces utilizaba la tarjeta de crédito, además, afirmó que debía cuidar la imagen del comandante en Jefe.  La anterior declaración ocurre en el marco del procesamiento a Oviedo, quienes es indagado por malversación de caudales públicos por 4.500 millones de pesos entre 2014 y 2018.  \n",
            "torch.Size([45, 1])\n",
            "category = 2 / text =   Como un hecho “lamentable y doloroso” calificó la Federación de Empresas de Turismo de Chile (Fedetur), la muerte de seis turistas brasileños que se encontraban de visita en el país, presumiblemente luego de inhalar monóxido de carbono.  De acuerdo a Fedetur, el departamento en que se encontraban en el centro de Santiago habría sido arrendado mediante la plataforma Airbnb.  El presidente de la entidad gremial, Ricardo Margulis, afirmó que “Lo ocurrido nos afecta como sector, ya que el objetivo de esta industria es que los turistas vivan experiencias agradables al visitar los distintos destinos de nuestro país, y no que suceda una situación amarga como esta”.        Las teorías con las que se trabaja para esclarecer la muerte de seis brasileños en Santiago    Así, reiteraron el llamado a las autoridades a regular la oferta informal de alojamiento , y reforzaron la recomendación a los turistas nacionales y extranjeros a que opten por servicios de alojamiento formal registrados en Sernatur.  “No se trata sólo de un tema tributario, sino que hay otros asuntos tanto o más relevantes que se deben abordar, como es garantizar la seguridad de los turistas. La oferta informal no está sometida a los controles y fiscalizaciones de los servicios formales de alojamiento, y por lo mismo, existe un alto riesgo de que hechos de esta naturaleza ocurran, como sucedió ayer”, expresó Ricardo Margulis.  El personero insistió en que se debe actuar proactivamente en esta materia, para así evitar que situaciones como esta se repitan, considerando el impacto que tienen en la imagen del turismo, ya que se ven afectadas vidas humanas.  El representante del gremio concluyó destacando que Brasil es un mercado estratégico para el turismo nacional, especialmente en este período del año, donde vienen muchos visitantes de ese país a disfrutar la temporada de nieve en los centros de esquí.  \n",
            "torch.Size([50, 1])\n",
            "category = 3 / text =   El Gobierno decidió retirar el decreto en donde proponía sólo hombres para el directorio de TVN, lo anterior luego de defender que la ley que obliga la paridad de género entraba en vigencia el 3 de mayo.  En entrevista con Expreso Bío Bío, el exintegrante del directorio de TVN Nissim Sharim, explicó la manera de trabajar del canal tras la decisión del Gobierno.        Gobierno admite error al plantear sólo hombres en directorio de TVN: oposición valora gesto    “ La designación de las personas que integran el directorio está mal concebida . Una cosa es que el poder ejecutivo designe a las personas de su confianza y otra es que se integre un directorio de un canal donde lo principal debería ser la actividad artística e informativa”.  Sobre su experiencia como miembro del directorio durante el gobierno de Ricardo Lagos, aclaró que “no había nadie que entendiera de comunicación, era gente importante en otros planos, pero nadie entendía lo que había que hacer con la comunicación. El asunto se agudizó en la medida que se trataba de poner una programación en el canal que respondiera a las expectativas de la gente “.  A su vez, se refirió al énfasis económico que en sus años se le agregaba al canal por sobre el contenido, lo que indicó “fueron experiencias frustrantes. Resulta que para organizar una producción se median parámetros económicos y cuando los parámetros económicos no eran favorables, se rechazaba cualquier idea y la verdad muchas veces se hacía trampa con eso “.        No incorporaba mujeres: Gobierno retira propuesta para directorio de TVN    Sobre la designación del directorio, Sharim informó que “en cualquier empresa, en cualquier organización si designas a las personas, por muy importantes que sean en sus planos, pero designan a personas que no tienen idea de lo que es la organización en la que participan, podría haber un fracaso aunque tengan buenas ideas en negocios y las platas que entran y salen “.  Para Sharim la estabilidad real se forma cuando “interviene gente que es idónea al respecto y eso me parece que hace mucho tiempo que no ocurre, de gente que entienda el asunto de la comunicación, televisión y elaboración de programas “.  Escucha la entrevista completa aquí:   \n",
            "torch.Size([8, 1])\n",
            "category = 3 / text =   Puede que en el cine hayan sido tan letales contra los humanos como entre ellos mismos, pero en la vida real, Alien y Depredador son dos seres de corazón tierno. Tanto, que decidieron compartir con los penquistas en pleno centro de Concepción.  Esa fue la sorpresa con la que se toparon los transeúntes en la esquina de Barros Arana con Castellón este viernes por la noche, cuando estos dos xenomorfos se tomaron fotografías… con quienes se atrevieran .  Con sus cerca de 2.5 metros de alto y ojos… bueno, en realidad casi no tiene ojos, Alien era quien se robaba todas las miradas, seguido de cerca por Depredador, con su mira láser y máscara que dejaba al descubierto su inconfundible rostro.  Si se topan con ellos, denles un abrazo, unas monedas, y luego huyan por sus vidas .   Christian Leal | BBCL   \n",
            "torch.Size([37, 1])\n",
            "category = 1 / text =   La policía de Malasia incautó una gran cantidad de bolsos de diseñadores, muchos de ellos llenos de dinero y de joyas , durante el allanamiento a las casas y las oficinas del exprimer ministro, Najib Razak, indicaron este viernes medios locales.  “Nuestro personal inspeccionó estos bolsos y descubrió varias divisas, incluyendo ringgit malayos, dólares estadounidenses, relojes y joyas en 72 bolsos” , dijo el director de unidad de la policía que investiga los delitos comerciales, Amar Singh.  El policía dijo que, por el momento, no es posible estimar el valor de las incautaciones debido a su gran volumen.  El allanamiento se produjo en el marco de las investigaciones lanzadas por el nuevo gobierno sobre un enorme escándalo de desvío de fondos públicos.  El nuevo gobierno, proveniente de las legislativas del 10 de mayo, dirigido por Mahathir Mohamad, de 92 años, dijo que quería recuperar los fondos desviados del para el desarrollo del 1Malaysia Development Berhad (1MDB), creado por Najib poco después de su llegada al poder en 2009 y que hoy acumula una deuda de 10.000 millones de euros.  El otrora gobernante, sobre quien pesan sospechas de que desvió fondos por 640 millones de euros , siempre ha negado cualquier acto ilícito.  Según Singh, entre los bolsos incautados, hay artículos de marcas como Hermes y Louis Vuitton, entre otras.  La mujer de Najib, Rosmah Mansor, muy impopular en el país por sus gastos extravagantes, posee una vasta colección de ropa de diseñadores y de bolsos de lujo, según la prensa.  Su reputación contribuyó a las acusaciones de que el gobierno saliente había perdido el contacto con los problemas de la gente de clase media.  \n",
            "torch.Size([34, 1])\n",
            "category = 3 / text =   Una profesora de 51 años es actualmente la prioridad para recibir un trasplante de hígado , luego que se le complicara una hepatitis crónica autoinmune. Jenny Manzo es de Iquique, pero debido a las complicaciones que ha enfrentado debió ser trasladada a la Clínica Dávila, ubicada en la región Metropolitana.  En conversación con el programa Expreso Bío Bío de La Radio, Sandra Semler, hija del esposo de Jenny Manzo, explicó que “su estado es muy crítico y grave debido a que lamentablemente su enfermedad empeoró desde el miércoles. Estamos es la espera de lo que nos digan los médicos en este momento”.  Actualmente, la profesora se encuentra conectada a un ventilador mecánico. “En estos momentos está sedada, está siendo dializada porque lamentablemente sus riñones no están funcionando (…) Lamentablemente cuando Jenny estaba bien, estable dentro de su gravedad, no se pudo optar por el trasplante fallido que no sabemos el motivo de por qué no llegaron esos órganos”, añadió Semler.        Profesora iquiqueña es prioridad para recibir hígado: esposo critica donación fallida desde Temuco    “¿Quién sabe si esos órganos podrían haber ayudado a salvar la vida de Jenny en ese momento?”, cuestionó Semler con respecto a la donación fallida de órganos de Joaquín Bustos .  Semler además entregó un mensaje como familia, pidiendo que “se haga consciencia a nivel humano más que nada. Si tenemos familiares que están críticos y tenemos la opción de donar órganos, que la familia no se niegue”.  Además pidió al Gobierno que “decrete una ley para que no pase esto . Que por falta de medios, aviones, recursos, no se logre que personas puedan ser trasplantadas o seguir viviendo”.  Semler aseguró que actualmente “estamos esperando casi un milagro”.  Escucha la entrevista completa a continuación:   \n",
            "torch.Size([63, 1])\n",
            "category = 1 / text =   El desembarco en Libia de 108 inmigrantes rescatados en el Mediterráneo por un barco comercial generó indignación en Italia entre las organizaciones humanitarias y algunos sectores políticos.  El barco Asso Ventotto, con bandera italiana, rescató el lunes a los inmigrantes en una barcaza a unas 60 millas náuticas (unos 110 km) al noroeste de Trípoli (Libia), según datos oficiales del tráfico marítimo.  En esos casos la Guardia Costera italiana, que coordina las operaciones, suele trasladarlos a Italia.        Ai Weiwei y Marea humana: la crisis mundial de los refugiados e inmigrantes en Chile    Pero desde junio, el gobierno italiano impide el desembarco de los migrantes ilegales y los entrega a los guardacostas libios.  “Libia no es un puerto seguro y se estarían violando leyes internacionales”, denunció el Alto Comisionado de las Naciones Unidas para los Refugiados (Acnur).  “Se trata de una verdadera represión colectiva”, sostiene Nicola Fratoianni, diputado italiano de izquierda, actualmente a bordo de un barco de una ONG española, que escuchó los intercambios radiales con la nave.        Reunión Trump-Conte en la Casa Blanca: dos gobernantes muy parecidos    Para la ONG alemana Sea-Watch se trata de la “primera repatriación por parte de un barco italiano en años”, comentó.  En el 2012, el Tribunal Europeo de Derechos Humanos condenó a Italia después de que un barco militar italiano entregara inmigrantes a Libia en 2009, entonces liderada por Muammar Gaddafi, quien había suscrito una serie de acuerdos con Italia antes de su caída en 2011.  En Libia los inmigrantes africanos son detenidos en forma arbitraria, sufren el abuso, la violencia y la extorsión, mientras que en Italia el 40% de los que han solicitado asilo en los últimos años han obtenido un permiso de residencia.        450 inmigrantes que estaban a la deriva en el Mediterráneo tienen en pugna a Italia y Malta    “Libia no es un lugar seguro (…) no podemos desembarcar a los migrantes allá”, aseguró el lunes por la noche Roberto Fico, presidente de la Cámara de Diputados y dirigente del Movimiento 5 Estrellas (M5E), parte de la coalición gobernante.  Algunos sectores de la formación antisistema M5E, victoriosa en las elecciones, se oponen a la entrega de fragatas italianas a la guardia costera libia para la lucha contra inmigración y han pedido explicaciones a los dirigentes del movimiento.  Matteo Salvini, ministro del Interior y líder de la ultraderechista Liga, aliada de M5E, sin embargo, rechazó las críticas.        España rescata a 340 migrantes en medio del Mediterráneo: uno flotaba sobre un neumático    “En las últimas horas, la guardia costera libia rescató y llevó a 611 migrantes a Libia”, escribió el martes en las redes sociales.  “Las ONG protestan y los traficantes de seres humanos pierden ocasiones de negocios. Eso está bien, vamos a seguir así”, agregó, repitiendo su lema: “Puertos cerrados, corazones abiertos”.  \n",
            "torch.Size([66, 1])\n",
            "category = 1 / text =   Miles de opositores venezolanos, encabezados por el autoproclamado presidente interino Juan Guaidó, llamaron este miércoles en las calles a los militares a permitir la entrada de ayuda humanitaria y a desconocer al mandatario Nicolás Maduro, quien a su vez los llamó a mantenerse unidos y leales. “No disparen en contra de un pueblo que exige también por su familia. Es una orden, soldado de la patria (…) ¡Basta!. Pensaron que generarían miedo, pero estamos en 5.000 puntos” del país, dijo Guaidó, en una manifestación en la universidad central, en Caracas. Entre un tumulto de periodista y seguidores, Guaidó, con una bata médica que le regalaron, caminó con pacientes y enfermeros: “Nos hemos reencontrado en una mayoría poderosa que puede cambiar al país”, declaró. “Llegó Guaidó y la esperanza ya volvió”, cantaban sus seguidores. “Fuerza Armada recupera tu dignidad”, “Maduro usurpador”, rezaban pancartas de manifestantes en varios puntos del país, sonando cornetas, pitos y cacerolas. Guaidó, jefe del Parlamento de mayoría opositora, comentó además que recibió un “pleno respaldo” del presidente estadounidense, Donald Trump, quien lo llamó por teléfono.  Agence France-Presse  “Unidad monolítica” A primera hora, Maduro comandó maniobras militares en Fuerte Tiuna, mayor complejo militar en Caracas, donde denunció que “mercenarios desertores” buscan desde Colombia fracturar a la Fuerza Armada.  “Unidad monolítica! ¡Moral máxima! Llamo a la Fuerza Armada (…) a una gran renovación, a una gran revolución militar de la moral”, arengó Maduro a unos 2.500 soldados. Aunque la cúpula militar la calificó como un “engaño”, el líder opositor insiste en ofrecer amnistía a los militares que colaboren con una transición, buscando romper el sostén de Maduro, la Fuerza Armada. Washington, que no descarta una acción armada en Venezuela, llamó a los militares a apoyar la transición. En este pulso, Maduro encabeza varios actos oficiales. “¿Ustedes quieren que gobierne un títere de los gringos en Venezuela?, preguntó en un mitin. ¡Noooooooo!”, le respondieron. Revisa aquí la manifestación completa  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9AXJuwWGzDk",
        "colab_type": "text"
      },
      "source": [
        "Training the Network\n",
        "--------------------\n",
        "\n",
        "Now all it takes to train this network is show it a bunch of examples,\n",
        "have it make guesses, and tell it if it's wrong.\n",
        "\n",
        "For the loss function ``nn.NLLLoss`` is appropriate, since the last\n",
        "layer of the RNN is ``nn.LogSoftmax``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMBH46Hpv61_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 128\n",
        "model = Model(vocab_size, embedding_size, n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maTFi6B5CtrM",
        "colab_type": "code",
        "outputId": "4ef90438-3a52-48bc-89c6-2e7901b045a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "%%time\n",
        "all_losses = loop_training(batch=True, example_generator=randomTrainingExampleEmb)\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16.9 s, sys: 1.42 s, total: 18.3 s\n",
            "Wall time: 18.6 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiHofwFE9+qQSVf8bQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BxP7l0plmUb",
        "colab_type": "text"
      },
      "source": [
        "###Batch processing\n",
        "Same to previously, lets bachify.\n",
        "\n",
        "This function creates a batch of examples with size ``<text_length x batch_size>``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w9gpEAZoqhp",
        "colab_type": "code",
        "outputId": "a32aa8fd-fe69-4949-a1f8-f4f76181ad34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def randomTrainingBatchEmb(batch_size):\n",
        "    categories = []\n",
        "    texts = []\n",
        "    for _ in range(batch_size):\n",
        "        i = random.randint(0, len(y_train) - 1)\n",
        "        category = y_train[i]\n",
        "        categories.append(category)\n",
        "        \n",
        "        text = X_train[i]\n",
        "        texts.append(text)\n",
        "    \n",
        "    category_tensor = torch.tensor(categories, dtype=torch.long)\n",
        "    \n",
        "    indexed_texts = indexer.transform(texts)\n",
        "    max_length = max([len(text) for text in indexed_texts])\n",
        "    indexed_texts = [text+[vocab_size]*(max_length-len(text)) for text in indexed_texts]\n",
        "\n",
        "\n",
        "    text_tensor = torch.zeros([len(indexed_texts[0]),batch_size],dtype=torch.long)\n",
        "\n",
        "    for i,indexed_text in enumerate(indexed_texts):\n",
        "        for j,idx in enumerate(indexed_text):\n",
        "            text_tensor[j][i] = idx\n",
        "    \n",
        "    return categories, indexed_texts, category_tensor, text_tensor, \n",
        "\n",
        "category, text, category_tensor, text_tensor = randomTrainingBatchEmb(10)\n",
        "print(text_tensor.size())\n",
        "\n",
        "print('category =', category)\n",
        "print('text =', text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([226, 10])\n",
            "category = [2, 4, 4, 1, 2, 2, 1, 2, 2, 1]\n",
            "text = [[814, 562, 919, 690, 796, 659, 764, 401, 491, 814, 764, 678, 349, 796, 814, 753, 162, 859, 886, 128, 234, 830, 488, 491, 311, 227, 764, 872, 271, 229, 244, 537, 348, 606, 764, 335, 305, 418, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], [261, 869, 440, 135, 743, 192, 970, 938, 357, 261, 869, 440, 172, 384, 496, 347, 171, 793, 31, 31, 31, 996, 83, 604, 368, 588, 716, 358, 743, 135, 546, 996, 83, 135, 996, 83, 135, 996, 83, 135, 469, 996, 83, 135, 996, 83, 135, 996, 83, 135, 484, 20, 83, 135, 758, 996, 83, 603, 996, 83, 996, 83, 135, 817, 996, 83, 135, 539, 31, 996, 83, 31, 996, 83, 135, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], [955, 840, 806, 32, 949, 840, 61, 240, 40, 248, 142, 187, 933, 228, 971, 290, 598, 971, 50, 239, 598, 971, 134, 450, 126, 57, 925, 697, 32, 840, 182, 593, 127, 549, 187, 200, 228, 59, 866, 846, 529, 140, 124, 228, 59, 812, 660, 420, 430, 645, 598, 627, 421, 627, 529, 333, 430, 228, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], [915, 536, 280, 7, 115, 212, 198, 280, 246, 25, 518, 476, 869, 814, 32, 932, 794, 163, 167, 605, 567, 694, 919, 280, 70, 700, 773, 898, 151, 241, 869, 41, 459, 578, 57, 91, 168, 930, 930, 659, 451, 424, 292, 33, 68, 962, 280, 912, 459, 103, 568, 489, 536, 814, 578, 866, 866, 793, 814, 115, 722, 85, 57, 212, 311, 918, 727, 65, 70, 781, 210, 401, 181, 709, 151, 581, 737, 641, 897, 846, 254, 402, 519, 899, 158, 554, 615, 57, 613, 697, 292, 475, 708, 678, 3, 719, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], [511, 148, 938, 306, 209, 464, 681, 98, 895, 389, 252, 723, 133, 952, 895, 888, 64, 303, 932, 895, 322, 8, 364, 306, 741, 759, 836, 64, 622, 5, 223, 812, 936, 179, 965, 223, 940, 988, 130, 5, 257, 965, 303, 932, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], [150, 49, 571, 414, 711, 284, 974, 691, 696, 218, 27, 773, 163, 192, 139, 803, 711, 199, 696, 830, 587, 199, 711, 27, 770, 414, 711, 46, 803, 691, 743, 863, 974, 435, 497, 497, 974, 571, 98, 75, 490, 830, 950, 462, 788, 644, 746, 150, 216, 49, 995, 607, 287, 704, 607, 216, 809, 44, 160, 322, 160, 672, 746, 50, 820, 230, 370, 788, 696, 218, 287, 672, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], [40, 890, 846, 70, 912, 947, 247, 635, 203, 154, 1, 442, 736, 750, 203, 353, 787, 578, 106, 442, 592, 218, 974, 183, 879, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], [868, 983, 664, 1, 943, 383, 165, 362, 690, 996, 745, 629, 664, 943, 521, 963, 126, 743, 743, 278, 218, 661, 48, 661, 789, 272, 132, 218, 252, 148, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], [385, 329, 238, 64, 324, 690, 64, 40, 240, 872, 227, 692, 403, 188, 223, 458, 782, 958, 207, 411, 64, 457, 257, 329, 188, 163, 637, 64, 726, 996, 354, 502, 691, 784, 773, 600, 768, 279, 83, 999, 218, 5, 940, 142, 411, 430, 411, 872, 807, 64, 975, 385, 728, 411, 385, 329, 238, 64, 324, 690, 64, 40, 240, 86, 981, 642, 119, 594, 64, 525, 699, 361, 212, 812, 510, 745, 148, 983, 76, 641, 871, 278, 836, 830, 747, 470, 431, 450, 318, 424, 411, 683, 175, 260, 547, 701, 383, 686, 457, 318, 278, 149, 329, 79, 573, 974, 788, 188, 150, 49, 149, 318, 876, 785, 421, 658, 64, 243, 127, 636, 450, 450, 404, 654, 967, 849, 683, 273, 850, 520, 435, 497, 602, 88, 119, 583, 571, 421, 257, 977, 658, 257, 690, 257, 773, 850, 257, 504, 385, 594, 257, 972, 329, 773, 239, 735, 394, 665, 48, 412, 469, 157, 690, 594, 830, 53, 680, 354, 778, 318, 654, 943, 36, 256, 257, 861, 854, 257, 412, 258, 572, 979, 260, 306, 79, 521, 9, 652, 338, 897, 68, 32, 460, 598, 690, 227, 872, 303, 990, 344, 933, 344, 598, 394, 639, 830, 747, 720, 433, 521, 64, 494, 812, 690, 521, 149, 318, 278, 785, 288, 431, 788, 318, 836, 246, 275], [635, 493, 720, 310, 274, 561, 515, 115, 766, 715, 568, 970, 226, 348, 941, 167, 308, 373, 565, 623, 515, 838, 995, 713, 100, 377, 611, 167, 573, 115, 76, 493, 970, 676, 312, 354, 51, 568, 889, 760, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7rCYKW_Pxlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(vocab_size, embedding_size, n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVWxHrVeC4if",
        "colab_type": "code",
        "outputId": "67673cf1-942b-4171-8c2b-572d771f827b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "all_losses = loop_training(batch=10, example_generator=randomTrainingBatchEmb)\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15.1 s, sys: 198 ms, total: 15.3 s\n",
            "Wall time: 15.4 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81CLzT2yR8zJ",
        "colab_type": "text"
      },
      "source": [
        "## Credits\n",
        "\n",
        "The news text documents belong to [Biobio Chile](https://www.biobiochile.cl/), [licence Creative Commons (CC-BY-NC)](https://creativecommons.org/licenses/by-nc/2.0/cl/).\n",
        "\n",
        "Part of the code developed is extracted from \n",
        "\n",
        "\n",
        "*   [https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)\n",
        "*   [https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)\n",
        "*   [https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)\n",
        "\n",
        "## Additional material\n",
        "For additional references visit [https://pytorch.org/tutorials/](https://pytorch.org/tutorials/)."
      ]
    }
  ]
}